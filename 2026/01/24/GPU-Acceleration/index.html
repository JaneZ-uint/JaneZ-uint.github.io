
<!DOCTYPE html>
<html lang="en">
    
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="Brain of JaneZ in a Jar">
    <title>GPU Acceleration - Brain of JaneZ in a Jar</title>
    <meta name="author" content="JaneZ">
    
    
    
    <script type="application/ld+json">{"@context":"http://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"JaneZ","sameAs":["https://github.com/JaneZ-uint","https://x.com/JaneZ0826"],"image":"https://www.gravatar.com/avatar/41c9cfd7e215b2ada7b022b845a390c3"},"articleBody":"给25级xpy 伟大思想的pre，一天时间搓出来的，放到blog上留作纪念。 也是第一次用vscode-marp 做ppt，终于摆脱office的阴间排版了。\n\nmarp: true\ntheme: gaia\nfooter: ‘JaneZ 2025-10-14’\npaginate: true\nhtml: true\nstyle: |\nsection a {\nfont-size: 30px;\n}GPU AccelerationYihan Zhu @JaneZ ACM Class 2024\n2025.10.14\nOverview\nBasic Architecture of CPU, GPU, RAM, Cache\nGPU Architecture\nGPU Programming\nCase study: Matrix Multiplication on GPU\n\nWhat is a GPU?\nCPU (中央处理器)\n拥有少量强大的核心 (Core)。\n具有复杂的控制单元 (Control) 和多级缓存 (L1, L2, L3 Cache)。\n擅长串行任务和复杂的控制逻辑。\n\n\n\nWhat is a GPU?\nGPU (图形处理器)\n拥有大量简单的核心 (Core)。\n适合处理并行任务和大规模数据。\n常用于图形渲染和机器学习等领域。\n\n\n\nWhat is RAM?\n随机存取存储器 (RAM) 是计算机的主要内存，用于存储正在使用的数据和程序。\n动态随机存取存储器 (DRAM)：容量大，速度较慢，常用于主内存。\n静态随机存取存储器 (SRAM)：速度快，容量小，常用于缓存(Cache)。\n\n\nCPU 可以直接、快速地访问内存中任何位置的数据，无需按顺序查找。内存只能在电脑通电时存储数据。一旦你关机、重启或断电，内存中的所有数据都会立刻消失。\n\nWhat is Cache?\n缓存 (Cache) 是一种高速存储器，位于 CPU&#x2F;GPU 和主内存(DRAM)之间。\nCPU 的运行速度极快，但访问主内存（DRAM，即“内存条”）的速度相对慢得多。这就形成了一个巨大的“速度鸿沟”。缓存就是为了弥补这个速度差而生的。它只存储 CPU&#x2F;GPU 最可能立即需要的数据和指令。\n多级缓存结构是现代 CPU 高性能的基础。\n\n\n\n\n缓存级别\n所属设备\n速度 &#x2F; 容量\n数据共享范围\n\n\n\nL1 缓存（SRAM）\nCPU &#x2F; GPU 核心内部\n最快 &#x2F; 容量最小\n核心独享（每个核心都有自己的 L1）\n\n\nL2 缓存\nCPU &#x2F; GPU 核心附近\n较快 &#x2F; 适中\n通常核心独享或小组共享\n\n\nL3 缓存\nCPU\n较慢 &#x2F; 容量最大\n所有核心共享\n\n\n共享内存\nGPU\n极快（用户可控）\n线程块内部协作共享\n\n\n\n\n\n特性\nCPU 缓存（L1 &#x2F; L2 &#x2F; L3）\nGPU 缓存（L1 &#x2F; L2 &#x2F; 共享内存）\n\n\n\n设计核心目标\n低延迟（Low Latency）：尽快完成单个复杂任务\n高吞吐量（High Throughput）：同时处理大量简单任务\n\n\n层级数\nL1、L2、L3 三级\n通常只有 L1、L2 两级\n\n\nL3 缓存\n有。容量大，供所有核心共享\n基本无。架构上更依赖 L2 和共享内存\n\n\n最特殊结构\nL3 缓存（复杂数据共享）\n共享内存（Shared Memory，程序员可控的高速存储）\n\n\n数据共享方式\n核心间通过 L3 缓存或总线进行数据同步\n线程块内部通过共享内存直接快速协作\n\n\nGPU Architecture现代 GPU（以 NVIDIA 的 CUDA 架构为例，如 Volta, Turing, Ampere, Hopper）从上到下可以分成三个主要层级：\n\n芯片级别：GPC (Graphics Processing Clusters) 整个 GPU 芯片由多个被称为 GPC (图形处理集群) 的大型单元组成。\n集群级别：SM (Streaming Multiprocessors) 每个 GPC 内部包含多个 SM (流式多处理器)。\n\nSM 是 GPU 的真正核心！ 它是执行并行计算的基本控制单元。\nGPU Architecture\nSM 内部：核心、Warp 和内存\n\n\nCUDAs 核心 (CUDA Cores)：大量（每个 SM 包含数十到数百个）。负责实际的数学运算（如加法、乘法）。\nWarp Scheduler： SM 的真正指挥官，负责将接收到的任务（线程块）拆解成 Warp（线程束，32 个线程一组），并向所有 32 个线程同时广播指令（SIMT 模型）\n共享内存&#x2F;L1 缓存：供 SM 内的线程块协作共享数据。\n寄存器堆：每个线程独享的高速存储单元。\n\nGPU Programming mode：SIMTSingle instruction multiple threads (SIMT) 单指令多线程\n\n所有线程执行相同的代码，但它们可以根据程序中的分支或条件语句采取不同的执行路径（例如 if&#x2F;else 结构）。\nThread (线程)：执行计算的基本单位。\nThread Block (线程块)：线程被分组到块中。同一块内的线程具有共享内存。\nGrid (网格)：线程块又被分组到网格中。\n\nSIMT on GPU Hardware\n一个 Grid 中的 Thread Blocks（线程块）会被分配到 GPU 的各个 SM 上执行。\n当一个线程块被分配到 SM 上时，SM 内的调度器会首先将这个线程块中的所有线程（通常是 128、 256 或 1024 个）分成多个 Warp（每个 Warp 32 个线程）。\n调度器的工作就是从就绪的 Warp 中选择一个，然后向该 Warp 中的所有 32 个线程同时发出相同的指令。\nGPU 不会调度单个线程，也不会调度整个线程块，它只以 Warp 为单位进行操作。\n\nCUDA cores当一个 Warp 被调度时，它会同时被送往 SM 内部的 CUDA 核心。在理想情况下（没有分支冲突），Warp 中的 32 个线程会同时在 32 个不同的 CUDA 核心上执行同一条指令。\nWe keep talking about CUDA,then you guys may ask: What is CUDA?\nCUDA (Compute Unified Device Architecture) 是 NVIDIA 提供的并行计算平台和编程模型。\n它允许开发者使用 C&#x2F;C++ 等高级语言编写程序，以充分利用 GPU 的强大计算能力。\nCUDA 提供了一套丰富的 API 和库，使得在 GPU 上进行高性能计算变得更加简单和高效。\n\nCUDA Programming Example: Vector Addition12345void VecAddCPU(float* A, float *B, float* C, int n) &#123; for (int i = 0; i &lt; n; ++i) &#123;   C[i] = A[i] + B[i]; &#125;&#125;\n\nCUDA Programming Example: Vector Addition123456__global__ void VecAddGPU(float* A, float *B, float* C, int n) &#123; int i = blockIdx.x * blockDim.x + threadIdx.x; if (i &lt; n) &#123;   C[i] = A[i] + B[i]; &#125;&#125;\n\nVector Addition (Host Code)12345678910111213void VecAddCUDA(float* Acpu, float *Bcpu, float* Ccpu, int n) &#123; float *dA, *dB, *dC; cudaMalloc(&amp;dA, n * sizeof(float)); cudaMalloc(&amp;dB, n * sizeof(float)); cudaMalloc(&amp;dC, n * sizeof(float)); cudaMemcpy(dA, Acpu, n * sizeof(float), cudaMemcpyHostToDevice); cudaMemcpy(dB, Bcpu, n * sizeof(float), cudaMemcpyHostToDevice); int threads_per_block = 512; int nblocks = (n + threads_per_block - 1) / threads_per_block; VecAddKernel&lt;&lt;&lt;nblocks, thread_per_block&gt;&gt;&gt;(dA, dB, dC, n); cudaMemcpy(Ccpu, dC, n * sizeof(float), cudaMemcpyDeviceToHost); cudaFree(dA); cudaFree(dB); cudaFree(dC);&#125;\n\nCase Study: Matrix Multiplication on GPU\nMatrix Multiplication (GEMM) 是线性代数中最基本的操作之一，广泛应用于科学计算、图形处理和机器学习等领域。\nCompute C &#x3D; dot(A.T, B)\n\nThread-level: register tiling大规模线程并行执行（多个线程），每个线程又极高效率地利用了寄存器（平铺）。\n类似于缓存+分块的思想\n12345678910111213141516__global__ void mm(float A[N][N], float B[N][N], float C[N][N]) &#123; int ybase = blockIdx.y * blockDim.y + threadIdx.y; int xbase = blockIdx.x * blockDim.x + threadIdx.x; float c[V][V] = &#123;0&#125;; float a[V], b[V]; for (int k = 0; k &lt; N; ++k) &#123; a[:] = A[k, ybase*V : ybase*V + V]; b[:] = B[k, xbase*V : xbase*V + V]; for (int y = 0; y &lt; V; ++y) &#123; for (int x = 0; x &lt; V; ++x) &#123; c[y][x] += a[y] * b[x]; &#125; &#125; &#125; C[ybase * V : ybase*V + V, xbase*V : xbase*V + V] = c[:];&#125;\n\nBlock-level: shared memory tiling整个 Thread Block (线程块) 作为一个协作团队工作\nBlock-level: shared memory tiling\n平铺 (Tiling): 矩阵 A^T 和 B 被分解成大小为 L×S 或 S×L 的大块。\n协作 (Cooperation): 线程块中的所有线程首先协同工作，将 A^T 和 B 的当前大块从慢速的全局内存（Global Memory）一次性搬运到快速的共享内存（Shared Memory）中。\n重用 (Reuse): 一旦数据进入共享内存，块内的所有线程都可以多次、快速地访问这些数据，极大地提高了计算效率。\n\n123456789101112131415161718192021222324252627__global__ void mm(float A[N][N], float B[N][N], float C[N][N]) &#123; __shared__ float sA[S][L], sB[S][L]; float c[V][V] = &#123;0&#125;; float a[V], b[V]; int yblock = blockIdx.y; int xblock = blockIdx.x; for (int ko = 0; ko &lt; N; ko += S) &#123; __syncthreads(); // needs to be implemented by thread cooperative fetching sA[:, :] = A[k : k + S, yblock * L : yblock * L + L]; sB[:, :] = B[k : k + S, xblock * L : xblock * L + L]; __syncthreads(); for (int ki = 0; ki &lt; S; ++ ki) &#123; a[:] = sA[ki, threadIdx.y * V : threadIdx.y * V + V]; b[:] = sB[ki, threadIdx.x * V : threadIdx.x * V + V]; for (int y = 0; y &lt; V; ++y) &#123; for (int x = 0; x &lt; V; ++x) &#123; c[y][x] += a[y] * b[x]; &#125; &#125; &#125; &#125; int ybase = blockIdx.y * blockDim.y + threadIdx.y; int xbase = blockIdx.x * blockDim.x + threadIdx.x; C[ybase * V : ybase*V + V, xbase*V : xbase*V + V] = c[:];&#125;\n\nThanks for listening!AcknowledgementsCMU 10-414&#x2F;714: Deep Learning Systems by Prof. Tianqi Chen and Zico Kolter.\n","dateCreated":"2026-01-24T00:46:50+08:00","dateModified":"2026-01-24T01:10:12+08:00","datePublished":"2026-01-24T00:46:50+08:00","description":"","headline":"GPU Acceleration","image":[],"mainEntityOfPage":{"@type":"WebPage","@id":"https://janez-uint.github.io/2026/01/24/GPU-Acceleration/"},"publisher":{"@type":"Organization","name":"JaneZ","sameAs":["https://github.com/JaneZ-uint","https://x.com/JaneZ0826"],"image":"https://www.gravatar.com/avatar/41c9cfd7e215b2ada7b022b845a390c3","logo":{"@type":"ImageObject","url":"https://www.gravatar.com/avatar/41c9cfd7e215b2ada7b022b845a390c3"}},"url":"https://janez-uint.github.io/2026/01/24/GPU-Acceleration/"}</script>
    <meta name="description" content="给25级xpy 伟大思想的pre，一天时间搓出来的，放到blog上留作纪念。 也是第一次用vscode-marp 做ppt，终于摆脱office的阴间排版了。  marp: true theme: gaia footer: ‘JaneZ 2025-10-14’ paginate: true html: true style: | section a { font-size: 30px; }GPU">
<meta property="og:type" content="blog">
<meta property="og:title" content="GPU Acceleration">
<meta property="og:url" content="https://janez-uint.github.io/2026/01/24/GPU-Acceleration/index.html">
<meta property="og:site_name" content="Brain of JaneZ in a Jar">
<meta property="og:description" content="给25级xpy 伟大思想的pre，一天时间搓出来的，放到blog上留作纪念。 也是第一次用vscode-marp 做ppt，终于摆脱office的阴间排版了。  marp: true theme: gaia footer: ‘JaneZ 2025-10-14’ paginate: true html: true style: | section a { font-size: 30px; }GPU">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2026-01-23T16:46:50.000Z">
<meta property="article:modified_time" content="2026-01-23T17:10:12.540Z">
<meta property="article:author" content="JaneZ">
<meta name="twitter:card" content="summary">
<meta name="twitter:creator" content="@JaneZ0826">
    
    
        
    
    
    
    
    
    <!--STYLES-->
    
<link rel="stylesheet" href="/assets/css/all.css">

    
<link rel="stylesheet" href="/assets/css/jquery.fancybox.css">

    
<link rel="stylesheet" href="/assets/css/thumbs.css">

    
<link rel="stylesheet" href="/assets/css/tranquilpeak.css">

    <!--STYLES END-->
    

    

    
        
    
</head>

    <body>
        <div id="blog">
            <!-- Define author's picture -->


    

<header id="header" data-behavior="4">
    <i id="btn-open-sidebar" class="fa fa-lg fa-bars"></i>
    <div class="header-title">
        <a
            class="header-title-link"
            href="/"
            aria-label=""
        >
            Brain of JaneZ in a Jar
        </a>
    </div>
    
        
            <a
                class="header-right-picture "
                href="#about"
                aria-label="Open the link: /#about"
            >
        
        
        </a>
    
</header>

            <!-- Define author's picture -->


<nav id="sidebar" data-behavior="4">
    <div class="sidebar-container">
        
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/"
                            
                            rel="noopener"
                            title="Home"
                        >
                        <i class="sidebar-button-icon fa fa-home" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Home</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/all-categories"
                            
                            rel="noopener"
                            title="Categories"
                        >
                        <i class="sidebar-button-icon fa fa-bookmark" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Categories</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/all-tags"
                            
                            rel="noopener"
                            title="Tags"
                        >
                        <i class="sidebar-button-icon fa fa-tags" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Tags</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/all-archives"
                            
                            rel="noopener"
                            title="Archives"
                        >
                        <i class="sidebar-button-icon fa fa-archive" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Archives</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link open-algolia-search"
                            href="#search"
                            
                            rel="noopener"
                            title="Search"
                        >
                        <i class="sidebar-button-icon fa fa-search" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Search</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="#about"
                            
                            rel="noopener"
                            title="About"
                        >
                        <i class="sidebar-button-icon fa fa-question" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">About</span>
                    </a>
            </li>
            
        </ul>
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="https://github.com/JaneZ-uint"
                            
                                target="_blank"
                            
                            rel="noopener"
                            title="GitHub"
                        >
                        <i class="sidebar-button-icon fab fa-github" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">GitHub</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="https://x.com/JaneZ0826"
                            
                                target="_blank"
                            
                            rel="noopener"
                            title="Twitter"
                        >
                        <i class="sidebar-button-icon fab fa-twitter" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Twitter</span>
                    </a>
            </li>
            
        </ul>
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/atom.xml"
                            
                            rel="noopener"
                            title="RSS"
                        >
                        <i class="sidebar-button-icon fa fa-rss" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">RSS</span>
                    </a>
            </li>
            
        </ul>
        
    </div>
</nav>

            
            <div id="main" data-behavior="4"
                 class="
                        hasCoverMetaIn
                        ">
                
<article class="post">
    
    
        <div class="post-header main-content-wrap text-left">
    
        <h1 class="post-title">
            GPU Acceleration
        </h1>
    
    
        <div class="post-meta">
    <time datetime="2026-01-24T00:46:50+08:00">
	
		    Jan 24, 2026
    	
    </time>
    
</div>

    
</div>

    
    <div class="post-content markdown">
        <div class="main-content-wrap">
            <p>给25级xpy 伟大思想的pre，一天时间搓出来的，放到blog上留作纪念。 也是第一次用vscode-marp 做ppt，终于摆脱office的阴间排版了。</p>
<hr>
<p>marp: true</p>
<p>theme: gaia</p>
<p>footer: ‘JaneZ 2025-10-14’</p>
<p>paginate: true</p>
<p>html: true</p>
<p>style: |</p>
<p>section a {</p>
<p>font-size: 30px;</p>
<h2 id=""><a href="#" class="headerlink" title="}"></a>}</h2><h1 id="GPU-Acceleration"><a href="#GPU-Acceleration" class="headerlink" title="GPU Acceleration"></a>GPU Acceleration</h1><p>Yihan Zhu @JaneZ ACM Class 2024</p>
<p>2025.10.14</p>
<h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><ul>
<li>Basic Architecture of CPU, GPU, RAM, Cache</li>
<li>GPU Architecture</li>
<li>GPU Programming</li>
<li>Case study: Matrix Multiplication on GPU</li>
</ul>
<h2 id="What-is-a-GPU"><a href="#What-is-a-GPU" class="headerlink" title="What is a GPU?"></a>What is a GPU?</h2><ul>
<li>CPU (中央处理器)<ul>
<li>拥有少量强大的核心 (Core)。</li>
<li>具有复杂的控制单元 (Control) 和多级缓存 (L1, L2, L3 Cache)。</li>
<li>擅长串行任务和复杂的控制逻辑。</li>
</ul>
</li>
</ul>
<h2 id="What-is-a-GPU-1"><a href="#What-is-a-GPU-1" class="headerlink" title="What is a GPU?"></a>What is a GPU?</h2><ul>
<li>GPU (图形处理器)<ul>
<li>拥有大量简单的核心 (Core)。</li>
<li>适合处理并行任务和大规模数据。</li>
<li>常用于图形渲染和机器学习等领域。</li>
</ul>
</li>
</ul>
<h2 id="What-is-RAM"><a href="#What-is-RAM" class="headerlink" title="What is RAM?"></a>What is RAM?</h2><ul>
<li>随机存取存储器 (RAM) 是计算机的主要内存，用于存储正在使用的数据和程序。<ul>
<li>动态随机存取存储器 (DRAM)：容量大，速度较慢，常用于主内存。</li>
<li>静态随机存取存储器 (SRAM)：速度快，容量小，常用于缓存(Cache)。</li>
</ul>
</li>
<li>CPU 可以直接、快速地访问内存中任何位置的数据，无需按顺序查找。内存只能在电脑通电时存储数据。一旦你关机、重启或断电，内存中的所有数据都会立刻消失。</li>
</ul>
<h2 id="What-is-Cache"><a href="#What-is-Cache" class="headerlink" title="What is Cache?"></a>What is Cache?</h2><ul>
<li>缓存 (Cache) 是一种高速存储器，位于 CPU&#x2F;GPU 和主内存(DRAM)之间。</li>
<li>CPU 的运行速度极快，但访问主内存（DRAM，即“内存条”）的速度相对慢得多。这就形成了一个巨大的“速度鸿沟”。缓存就是为了弥补这个速度差而生的。它只存储 CPU&#x2F;GPU 最可能立即需要的数据和指令。</li>
<li>多级缓存结构是现代 CPU 高性能的基础。</li>
</ul>
<table>
<thead>
<tr>
<th>缓存级别</th>
<th>所属设备</th>
<th>速度 &#x2F; 容量</th>
<th>数据共享范围</th>
</tr>
</thead>
<tbody><tr>
<td>L1 缓存（SRAM）</td>
<td>CPU &#x2F; GPU 核心内部</td>
<td>最快 &#x2F; 容量最小</td>
<td>核心独享（每个核心都有自己的 L1）</td>
</tr>
<tr>
<td>L2 缓存</td>
<td>CPU &#x2F; GPU 核心附近</td>
<td>较快 &#x2F; 适中</td>
<td>通常核心独享或小组共享</td>
</tr>
<tr>
<td>L3 缓存</td>
<td>CPU</td>
<td>较慢 &#x2F; 容量最大</td>
<td>所有核心共享</td>
</tr>
<tr>
<td>共享内存</td>
<td>GPU</td>
<td>极快（用户可控）</td>
<td>线程块内部协作共享</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>特性</th>
<th>CPU 缓存（L1 &#x2F; L2 &#x2F; L3）</th>
<th>GPU 缓存（L1 &#x2F; L2 &#x2F; 共享内存）</th>
</tr>
</thead>
<tbody><tr>
<td>设计核心目标</td>
<td>低延迟（Low Latency）：尽快完成单个复杂任务</td>
<td>高吞吐量（High Throughput）：同时处理大量简单任务</td>
</tr>
<tr>
<td>层级数</td>
<td>L1、L2、L3 三级</td>
<td>通常只有 L1、L2 两级</td>
</tr>
<tr>
<td>L3 缓存</td>
<td>有。容量大，供所有核心共享</td>
<td>基本无。架构上更依赖 L2 和共享内存</td>
</tr>
<tr>
<td>最特殊结构</td>
<td>L3 缓存（复杂数据共享）</td>
<td>共享内存（Shared Memory，程序员可控的高速存储）</td>
</tr>
<tr>
<td>数据共享方式</td>
<td>核心间通过 L3 缓存或总线进行数据同步</td>
<td>线程块内部通过共享内存直接快速协作</td>
</tr>
</tbody></table>
<h2 id="GPU-Architecture"><a href="#GPU-Architecture" class="headerlink" title="GPU Architecture"></a>GPU Architecture</h2><p>现代 GPU（以 NVIDIA 的 CUDA 架构为例，如 Volta, Turing, Ampere, Hopper）从上到下可以分成三个主要层级：</p>
<ol>
<li>芯片级别：GPC (Graphics Processing Clusters) 整个 GPU 芯片由多个被称为 GPC (图形处理集群) 的大型单元组成。</li>
<li>集群级别：SM (Streaming Multiprocessors) 每个 GPC 内部包含多个 SM (流式多处理器)。</li>
</ol>
<p><strong>SM 是 GPU 的真正核心！ 它是执行并行计算的基本控制单元。</strong></p>
<h2 id="GPU-Architecture-1"><a href="#GPU-Architecture-1" class="headerlink" title="GPU Architecture"></a>GPU Architecture</h2><ol start="3">
<li>SM 内部：核心、Warp 和内存</li>
</ol>
<ul>
<li>CUDAs 核心 (CUDA Cores)：大量（每个 SM 包含数十到数百个）。负责实际的数学运算（如加法、乘法）。</li>
<li>Warp Scheduler： SM 的真正指挥官，负责将接收到的任务（线程块）拆解成 Warp（线程束，32 个线程一组），并向所有 32 个线程同时广播指令（SIMT 模型）</li>
<li>共享内存&#x2F;L1 缓存：供 SM 内的线程块协作共享数据。</li>
<li>寄存器堆：每个线程独享的高速存储单元。</li>
</ul>
<h2 id="GPU-Programming-mode：SIMT"><a href="#GPU-Programming-mode：SIMT" class="headerlink" title="GPU Programming mode：SIMT"></a>GPU Programming mode：SIMT</h2><p>Single instruction multiple threads (SIMT) 单指令多线程</p>
<ul>
<li>所有线程执行相同的代码，但它们可以根据程序中的分支或条件语句采取不同的执行路径（例如 if&#x2F;else 结构）。</li>
<li>Thread (线程)：执行计算的基本单位。</li>
<li>Thread Block (线程块)：线程被分组到块中。同一块内的线程具有共享内存。</li>
<li>Grid (网格)：线程块又被分组到网格中。</li>
</ul>
<h2 id="SIMT-on-GPU-Hardware"><a href="#SIMT-on-GPU-Hardware" class="headerlink" title="SIMT on GPU Hardware"></a>SIMT on GPU Hardware</h2><ul>
<li>一个 Grid 中的 Thread Blocks（线程块）会被分配到 GPU 的各个 SM 上执行。</li>
<li>当一个线程块被分配到 SM 上时，SM 内的调度器会首先将这个线程块中的所有线程（通常是 128、 256 或 1024 个）分成多个 Warp（每个 Warp 32 个线程）。</li>
<li>调度器的工作就是从就绪的 Warp 中选择一个，然后向该 Warp 中的所有 32 个线程同时发出相同的指令。</li>
<li>GPU 不会调度单个线程，也不会调度整个线程块，它只以 Warp 为单位进行操作。</li>
</ul>
<h2 id="CUDA-cores"><a href="#CUDA-cores" class="headerlink" title="CUDA cores"></a>CUDA cores</h2><p>当一个 Warp 被调度时，它会同时被送往 SM 内部的 CUDA 核心。在理想情况下（没有分支冲突），Warp 中的 32 个线程会同时在 32 个不同的 CUDA 核心上执行同一条指令。</p>
<h2 id="We-keep-talking-about-CUDA-then-you-guys-may-ask-What-is-CUDA"><a href="#We-keep-talking-about-CUDA-then-you-guys-may-ask-What-is-CUDA" class="headerlink" title="We keep talking about CUDA,then you guys may ask: What is CUDA?"></a>We keep talking about CUDA,then you guys may ask: What is CUDA?</h2><ul>
<li>CUDA (Compute Unified Device Architecture) 是 NVIDIA 提供的并行计算平台和编程模型。</li>
<li>它允许开发者使用 C&#x2F;C++ 等高级语言编写程序，以充分利用 GPU 的强大计算能力。</li>
<li>CUDA 提供了一套丰富的 API 和库，使得在 GPU 上进行高性能计算变得更加简单和高效。</li>
</ul>
<h2 id="CUDA-Programming-Example-Vector-Addition"><a href="#CUDA-Programming-Example-Vector-Addition" class="headerlink" title="CUDA Programming Example: Vector Addition"></a>CUDA Programming Example: Vector Addition</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">void VecAddCPU(float* A, float *B, float* C, int n) &#123;</span><br><span class="line"> for (int i = 0; i &lt; n; ++i) &#123;</span><br><span class="line">   C[i] = A[i] + B[i];</span><br><span class="line"> &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="CUDA-Programming-Example-Vector-Addition-1"><a href="#CUDA-Programming-Example-Vector-Addition-1" class="headerlink" title="CUDA Programming Example: Vector Addition"></a>CUDA Programming Example: Vector Addition</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">__global__ void VecAddGPU(float* A, float *B, float* C, int n) &#123;</span><br><span class="line"> int i = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line"> if (i &lt; n) &#123;</span><br><span class="line">   C[i] = A[i] + B[i];</span><br><span class="line"> &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="Vector-Addition-Host-Code"><a href="#Vector-Addition-Host-Code" class="headerlink" title="Vector Addition (Host Code)"></a>Vector Addition (Host Code)</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">void VecAddCUDA(float* Acpu, float *Bcpu, float* Ccpu, int n) &#123;</span><br><span class="line"> float *dA, *dB, *dC;</span><br><span class="line"> cudaMalloc(&amp;dA, n * sizeof(float));</span><br><span class="line"> cudaMalloc(&amp;dB, n * sizeof(float));</span><br><span class="line"> cudaMalloc(&amp;dC, n * sizeof(float));</span><br><span class="line"> cudaMemcpy(dA, Acpu, n * sizeof(float), cudaMemcpyHostToDevice);</span><br><span class="line"> cudaMemcpy(dB, Bcpu, n * sizeof(float), cudaMemcpyHostToDevice);</span><br><span class="line"> int threads_per_block = 512;</span><br><span class="line"> int nblocks = (n + threads_per_block - 1) / threads_per_block;</span><br><span class="line"> VecAddKernel&lt;&lt;&lt;nblocks, thread_per_block&gt;&gt;&gt;(dA, dB, dC, n);</span><br><span class="line"> cudaMemcpy(Ccpu, dC, n * sizeof(float), cudaMemcpyDeviceToHost);</span><br><span class="line"> cudaFree(dA); cudaFree(dB); cudaFree(dC);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="Case-Study-Matrix-Multiplication-on-GPU"><a href="#Case-Study-Matrix-Multiplication-on-GPU" class="headerlink" title="Case Study: Matrix Multiplication on GPU"></a>Case Study: Matrix Multiplication on GPU</h2><ul>
<li>Matrix Multiplication (GEMM) 是线性代数中最基本的操作之一，广泛应用于科学计算、图形处理和机器学习等领域。</li>
<li>Compute C &#x3D; dot(A.T, B)</li>
</ul>
<h2 id="Thread-level-register-tiling"><a href="#Thread-level-register-tiling" class="headerlink" title="Thread-level: register tiling"></a>Thread-level: register tiling</h2><p>大规模线程并行执行（多个线程），每个线程又极高效率地利用了寄存器（平铺）。</p>
<p>类似于缓存+分块的思想</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">__global__ void mm(float A[N][N], float B[N][N], float C[N][N]) &#123;</span><br><span class="line"> int ybase = blockIdx.y * blockDim.y + threadIdx.y;</span><br><span class="line"> int xbase = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line"> float c[V][V] = &#123;0&#125;;</span><br><span class="line"> float a[V], b[V];</span><br><span class="line"> for (int k = 0; k &lt; N; ++k) &#123;</span><br><span class="line"> a[:] = A[k, ybase*V : ybase*V + V];</span><br><span class="line"> b[:] = B[k, xbase*V : xbase*V + V];</span><br><span class="line"> for (int y = 0; y &lt; V; ++y) &#123;</span><br><span class="line"> for (int x = 0; x &lt; V; ++x) &#123;</span><br><span class="line"> c[y][x] += a[y] * b[x];</span><br><span class="line"> &#125;</span><br><span class="line"> &#125;</span><br><span class="line"> &#125;</span><br><span class="line"> C[ybase * V : ybase*V + V, xbase*V : xbase*V + V] = c[:];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="Block-level-shared-memory-tiling"><a href="#Block-level-shared-memory-tiling" class="headerlink" title="Block-level: shared memory tiling"></a>Block-level: shared memory tiling</h2><p>整个 Thread Block (线程块) 作为一个协作团队工作</p>
<h2 id="Block-level-shared-memory-tiling-1"><a href="#Block-level-shared-memory-tiling-1" class="headerlink" title="Block-level: shared memory tiling"></a>Block-level: shared memory tiling</h2><ul>
<li>平铺 (Tiling): 矩阵 A^T 和 B 被分解成大小为 L×S 或 S×L 的大块。</li>
<li>协作 (Cooperation): 线程块中的所有线程首先协同工作，将 A^T 和 B 的当前大块从慢速的全局内存（Global Memory）一次性搬运到快速的共享内存（Shared Memory）中。</li>
<li>重用 (Reuse): 一旦数据进入共享内存，块内的所有线程都可以多次、快速地访问这些数据，极大地提高了计算效率。</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">__global__ void mm(float A[N][N], float B[N][N], float C[N][N]) &#123;</span><br><span class="line"> __shared__ float sA[S][L], sB[S][L];</span><br><span class="line"> float c[V][V] = &#123;0&#125;;</span><br><span class="line"> float a[V], b[V];</span><br><span class="line"> int yblock = blockIdx.y;</span><br><span class="line"> int xblock = blockIdx.x;</span><br><span class="line"> for (int ko = 0; ko &lt; N; ko += S) &#123;</span><br><span class="line"> __syncthreads();</span><br><span class="line"> // needs to be implemented by thread cooperative fetching</span><br><span class="line"> sA[:, :] = A[k : k + S, yblock * L : yblock * L + L];</span><br><span class="line"> sB[:, :] = B[k : k + S, xblock * L : xblock * L + L];</span><br><span class="line"> __syncthreads();</span><br><span class="line"> for (int ki = 0; ki &lt; S; ++ ki) &#123;</span><br><span class="line"> a[:] = sA[ki, threadIdx.y * V : threadIdx.y * V + V];</span><br><span class="line"> b[:] = sB[ki, threadIdx.x * V : threadIdx.x * V + V];</span><br><span class="line"> for (int y = 0; y &lt; V; ++y) &#123;</span><br><span class="line"> for (int x = 0; x &lt; V; ++x) &#123;</span><br><span class="line"> c[y][x] += a[y] * b[x];</span><br><span class="line"> &#125;</span><br><span class="line"> &#125;</span><br><span class="line"> &#125;</span><br><span class="line"> &#125;</span><br><span class="line"> int ybase = blockIdx.y * blockDim.y + threadIdx.y;</span><br><span class="line"> int xbase = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line"> C[ybase * V : ybase*V + V, xbase*V : xbase*V + V] = c[:];</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="Thanks-for-listening"><a href="#Thanks-for-listening" class="headerlink" title="Thanks for listening!"></a>Thanks for listening!</h2><h2 id="Acknowledgements"><a href="#Acknowledgements" class="headerlink" title="Acknowledgements"></a>Acknowledgements</h2><p>CMU 10-414&#x2F;714: Deep Learning Systems by Prof. Tianqi Chen and Zico Kolter.</p>

            


        </div>
    </div>
    <div id="post-footer" class="post-footer main-content-wrap">
        
        
            <div class="post-actions-wrap">
    <nav>
        <ul class="post-actions post-action-nav">
            <li class="post-action">
                
                    
                <a
                    class="post-action-btn btn btn--default tooltip--top"
                    href="/2026/01/24/25-Fall/"
                    data-tooltip="25 Fall"
                    aria-label="PREVIOUS: 25 Fall"
                >
                    
                        <i class="fa fa-angle-left" aria-hidden="true"></i>
                        <span class="hide-xs hide-sm text-small icon-ml">PREVIOUS</span>
                    </a>
            </li>
            <li class="post-action">
                
                    
                <a
                    class="post-action-btn btn btn--default tooltip--top"
                    href="/2026/01/23/Enjoy-Your-Assassyn/"
                    data-tooltip="Enjoy Your Assassyn"
                    aria-label="NEXT: Enjoy Your Assassyn"
                >
                    
                        <span class="hide-xs hide-sm text-small icon-mr">NEXT</span>
                        <i class="fa fa-angle-right" aria-hidden="true"></i>
                    </a>
            </li>
        </ul>
    </nav>
    <ul class="post-actions post-action-share">
        <li class="post-action hide-lg hide-md hide-sm">
            <a
                class="post-action-btn btn btn--default btn-open-shareoptions"
                href="#btn-open-shareoptions"
                aria-label="Share this post"
            >
                <i class="fa fa-share-alt" aria-hidden="true"></i>
            </a>
        </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="https://www.facebook.com/sharer/sharer.php?u=https://janez-uint.github.io/2026/01/24/GPU-Acceleration/"
                    title="Share on Facebook"
                    aria-label="Share on Facebook"
                >
                    <i class="fab fa-facebook" aria-hidden="true"></i>
                </a>
            </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="https://twitter.com/intent/tweet?text=https://janez-uint.github.io/2026/01/24/GPU-Acceleration/"
                    title="Share on Twitter"
                    aria-label="Share on Twitter"
                >
                    <i class="fab fa-twitter" aria-hidden="true"></i>
                </a>
            </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="https://plus.google.com/share?url=https://janez-uint.github.io/2026/01/24/GPU-Acceleration/"
                    title="Share on Google+"
                    aria-label="Share on Google+"
                >
                    <i class="fab fa-google-plus" aria-hidden="true"></i>
                </a>
            </li>
        
        
            
        
        <li class="post-action">
            
                <a class="post-action-btn btn btn--default" href="#" aria-label="Back to top">
            
                <i class="fa fa-list" aria-hidden="true"></i>
            </a>
        </li>
    </ul>
</div>


        
        
            
        
    </div>
</article>



                <footer id="footer" class="main-content-wrap">
    <span class="copyrights">
        Copyrights &copy; 2026 JaneZ. All Rights Reserved.
    </span>
</footer>

            </div>
            
                <div id="bottom-bar" class="post-bottom-bar" data-behavior="4">
                    <div class="post-actions-wrap">
    <nav>
        <ul class="post-actions post-action-nav">
            <li class="post-action">
                
                    
                <a
                    class="post-action-btn btn btn--default tooltip--top"
                    href="/2026/01/24/25-Fall/"
                    data-tooltip="25 Fall"
                    aria-label="PREVIOUS: 25 Fall"
                >
                    
                        <i class="fa fa-angle-left" aria-hidden="true"></i>
                        <span class="hide-xs hide-sm text-small icon-ml">PREVIOUS</span>
                    </a>
            </li>
            <li class="post-action">
                
                    
                <a
                    class="post-action-btn btn btn--default tooltip--top"
                    href="/2026/01/23/Enjoy-Your-Assassyn/"
                    data-tooltip="Enjoy Your Assassyn"
                    aria-label="NEXT: Enjoy Your Assassyn"
                >
                    
                        <span class="hide-xs hide-sm text-small icon-mr">NEXT</span>
                        <i class="fa fa-angle-right" aria-hidden="true"></i>
                    </a>
            </li>
        </ul>
    </nav>
    <ul class="post-actions post-action-share">
        <li class="post-action hide-lg hide-md hide-sm">
            <a
                class="post-action-btn btn btn--default btn-open-shareoptions"
                href="#btn-open-shareoptions"
                aria-label="Share this post"
            >
                <i class="fa fa-share-alt" aria-hidden="true"></i>
            </a>
        </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="https://www.facebook.com/sharer/sharer.php?u=https://janez-uint.github.io/2026/01/24/GPU-Acceleration/"
                    title="Share on Facebook"
                    aria-label="Share on Facebook"
                >
                    <i class="fab fa-facebook" aria-hidden="true"></i>
                </a>
            </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="https://twitter.com/intent/tweet?text=https://janez-uint.github.io/2026/01/24/GPU-Acceleration/"
                    title="Share on Twitter"
                    aria-label="Share on Twitter"
                >
                    <i class="fab fa-twitter" aria-hidden="true"></i>
                </a>
            </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="https://plus.google.com/share?url=https://janez-uint.github.io/2026/01/24/GPU-Acceleration/"
                    title="Share on Google+"
                    aria-label="Share on Google+"
                >
                    <i class="fab fa-google-plus" aria-hidden="true"></i>
                </a>
            </li>
        
        
            
        
        <li class="post-action">
            
                <a class="post-action-btn btn btn--default" href="#" aria-label="Back to top">
            
                <i class="fa fa-list" aria-hidden="true"></i>
            </a>
        </li>
    </ul>
</div>


                </div>
                
    <div id="share-options-bar" class="share-options-bar" data-behavior="4">
        <i id="btn-close-shareoptions" class="fa fa-times"></i>
        <ul class="share-options">
            
                
                
                <li class="share-option">
                    <a
                        class="share-option-btn"
                        target="new"
                        href="https://www.facebook.com/sharer/sharer.php?u=https://janez-uint.github.io/2026/01/24/GPU-Acceleration/"
                        aria-label="Share on Facebook"
                    >
                        <i class="fab fa-facebook" aria-hidden="true"></i><span>Share on Facebook</span>
                    </a>
                </li>
            
                
                
                <li class="share-option">
                    <a
                        class="share-option-btn"
                        target="new"
                        href="https://twitter.com/intent/tweet?text=https://janez-uint.github.io/2026/01/24/GPU-Acceleration/"
                        aria-label="Share on Twitter"
                    >
                        <i class="fab fa-twitter" aria-hidden="true"></i><span>Share on Twitter</span>
                    </a>
                </li>
            
                
                
                <li class="share-option">
                    <a
                        class="share-option-btn"
                        target="new"
                        href="https://plus.google.com/share?url=https://janez-uint.github.io/2026/01/24/GPU-Acceleration/"
                        aria-label="Share on Google+"
                    >
                        <i class="fab fa-google-plus" aria-hidden="true"></i><span>Share on Google+</span>
                    </a>
                </li>
            
        </ul>
    </div>


            
        </div>
        


<div id="about">
    <div id="about-card">
        <div id="about-btn-close">
            <i class="fa fa-times"></i>
        </div>
        
            <h4 id="about-card-name">JaneZ</h4>
        
            <div id="about-card-bio"><p>author.bio</p>
</div>
        
        
            <div id="about-card-job">
                <i class="fa fa-briefcase"></i>
                <br/>
                <p>author.job</p>

            </div>
        
        
            <div id="about-card-location">
                <i class="fa fa-map-marker-alt"></i>
                <br/>
                Shanghai, China
            </div>
        
    </div>
</div>

        
        
<div id="cover" style="background-image:url('/assets/images/cover.jpg');"></div>
        <!--SCRIPTS-->

<script src="/assets/js/jquery.js"></script>


<script src="/assets/js/jquery.fancybox.js"></script>


<script src="/assets/js/thumbs.js"></script>


<script src="/assets/js/tranquilpeak.js"></script>

<!--SCRIPTS END-->


    




    </body>
</html>
